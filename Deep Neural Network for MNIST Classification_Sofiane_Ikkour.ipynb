{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Neural Network for MNIST Classification_Sofiane_Ikkour.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOTtCJgLFF8fLmnTgsWlFjg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7e62455cc76147159dd40e520dd76688":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5db27bc8d2e84ab282519346c0b6f304","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce94d08f928440ff8677410a443c5c03","IPY_MODEL_c60bc6f626ad4d1e95ca8d2cb30206a9","IPY_MODEL_3719358145e34ad58da6618fd8b2e886"]}},"5db27bc8d2e84ab282519346c0b6f304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce94d08f928440ff8677410a443c5c03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f755bdff31de48fca834bcb18139907f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Dl Completed...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_600b6e644fd04ef1bb9c6e72623f478d"}},"c60bc6f626ad4d1e95ca8d2cb30206a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b589a74992e64ef6aecf30abc82aa3df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e56c55c1f69449d8acd02f8f18433777"}},"3719358145e34ad58da6618fd8b2e886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8b08c4cf12884ef8bfd92586a0510758","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4/4 [00:00&lt;00:00, 11.47 file/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ec706cbd77949598fcd68a6cb6fb197"}},"f755bdff31de48fca834bcb18139907f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"600b6e644fd04ef1bb9c6e72623f478d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b589a74992e64ef6aecf30abc82aa3df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e56c55c1f69449d8acd02f8f18433777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b08c4cf12884ef8bfd92586a0510758":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0ec706cbd77949598fcd68a6cb6fb197":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# **Deep Neural Network for MNIST Classification**"],"metadata":{"id":"1amlGbkJlJPF"}},{"cell_type":"markdown","source":["The goal of this work is to write a program capable of detecting which digit is written based on the MNIST dataset. The MNIST dataset refers to handwritten digit recognition and provides 70000 images (28x28 pixels) of handwritten digits (1 digit per image). This classification is a problem with 10 classes since we have 10 digits (0,1,2,3,4,5,6,7,8,9). \n","We aim at building a neural network with 2 hidden layers.  \n","\n","Note: this code was written on Google Colab."],"metadata":{"id":"Mxoia0u6lbNq"}},{"cell_type":"markdown","source":["**Import the relevant packages**"],"metadata":{"id":"EXnBhIdvoZna"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydZcSjr7lIqH"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds # this package provides access to the MNIST dataset"]},{"cell_type":"markdown","source":["**Data preprocessing**"],"metadata":{"id":"Qtdx4u8nQBSg"}},{"cell_type":"code","source":["# Load the MNIST dataset\n","mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n","\n","# the argument name helps us specify the name of the dataset we want to load\n","# the argument with_info returns a tuple that stores information about the dataset\n","# the argument as_supervised, when True, returns a 2-tuple structure (input, target), when False, it returns a dictionary containg all the features\n","# the argument split splits the dataset into a train and test sets\n","\n","# now let's extract the train and test set separately\n","mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"],"metadata":{"id":"uFaCWRD0o72I","colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["7e62455cc76147159dd40e520dd76688","5db27bc8d2e84ab282519346c0b6f304","ce94d08f928440ff8677410a443c5c03","c60bc6f626ad4d1e95ca8d2cb30206a9","3719358145e34ad58da6618fd8b2e886","f755bdff31de48fca834bcb18139907f","600b6e644fd04ef1bb9c6e72623f478d","b589a74992e64ef6aecf30abc82aa3df","e56c55c1f69449d8acd02f8f18433777","8b08c4cf12884ef8bfd92586a0510758","0ec706cbd77949598fcd68a6cb6fb197"]},"executionInfo":{"status":"ok","timestamp":1642374772822,"user_tz":-60,"elapsed":1444,"user":{"displayName":"Sofiane Ikkour","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12163968403439377340"}},"outputId":"9c25f73c-6039-4193-82ae-efcbaec5241f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n","local data directory. If you'd instead prefer to read directly from our public\n","GCS bucket (recommended if you're running on GCP), you can instead pass\n","`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e62455cc76147159dd40e520dd76688","version_minor":0,"version_major":2},"text/plain":["Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"]}]},{"cell_type":"code","source":["# print the mnist_train set to see what it looks like\n","mnist_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZtmND4PQQeq","executionInfo":{"status":"ok","timestamp":1642374775465,"user_tz":-60,"elapsed":224,"user":{"displayName":"Sofiane Ikkour","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12163968403439377340"}},"outputId":"64ebd787-093f-467a-aaf7-708b0ab947a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# tensorflow has a training and test datasets by default\n","# however it doesn't have a validation set, so we need to do the split ourselves\n","# first let's see what the variable mnist_info looks like\n","mnist_info"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUZA2Yc938D4","executionInfo":{"status":"ok","timestamp":1642374776728,"user_tz":-60,"elapsed":7,"user":{"displayName":"Sofiane Ikkour","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12163968403439377340"}},"outputId":"44b73a8b-332f-43b6-ac29-c11d87d9824f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tfds.core.DatasetInfo(\n","    name='mnist',\n","    version=3.0.1,\n","    description='The MNIST database of handwritten digits.',\n","    homepage='http://yann.lecun.com/exdb/mnist/',\n","    features=FeaturesDict({\n","        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n","        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n","    }),\n","    total_num_examples=70000,\n","    splits={\n","        'test': 10000,\n","        'train': 60000,\n","    },\n","    supervised_keys=('image', 'label'),\n","    citation=\"\"\"@article{lecun2010mnist,\n","      title={MNIST handwritten digit database},\n","      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n","      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n","      volume={2},\n","      year={2010}\n","    }\"\"\",\n","    redistribution_info=,\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# mnist_info is a variable that stores multiple items\n","# the items (some of them are dictionaries) needed to define a validation set are \"splits\" and \"total_num_examples\" \n","\n","# we're going to define the number of validation samples as % of the training samples.  \n","num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples # 10% of the samples extracted\n","# we need to convert this variable to an integer\n","num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n","\n","# we also need to define a variable in which we can store the number of test samples\n","# this will avoid using the minst_inf.splits method to extract the test samples when we need to\n","num_test_samples = mnist_info.splits['test'].num_examples\n","num_test_samples = tf.cast(num_test_samples, tf.int64) # convert the variable to an integer\n","\n","# next step is to scale our data in order to have inputs between 0 and 1\n","# we write a function that accepts two inputs, an input image and a label\n","# the goal is to make the results more numerically stable as the input images will take values between 0 and 1\n","def scale(image, label):\n","  # first we convert the image to a float\n","  image = tf.cast(image, tf.float32)\n","  # image pixel intensities are comprised between 0 and 255 (256 shades of grey)\n","  # we divide each input by 255\n","  image /= 255.\n","  return image, label\n","\n","# use the method map to apply the function scale on the train and test sets\n","train_validation_scaled = mnist_train.map(scale)\n","test_scaled = mnist_test.map(scale)\n","\n","# once the data is scaled, we will define a buffer_size to shuffle it\n","buffer_size = 10000\n","# this buffer_size is a parameter we use when dealing with very large datasets\n","# in this case, the dataset cannot be shuffled at once as it can't be fit in memory\n","# so instead, tensorflow stores only samples at a time and shuffles them\n","\n","# use the shuffle method\n","train_validation_scaled_shuffled = train_validation_scaled.shuffle(buffer_size)\n","\n","# now that the train data is scaled and shuffled, we need to extract the validation data from it\n","# the number of validation samples is defined previously with num_validation_samples variable\n","# use the .take() method to extract that many samples\n","validation_data = train_validation_scaled_shuffled.take(num_validation_samples)\n","\n","# now we use the .skip() method to extract the rest of the data as train data\n","train_data = train_validation_scaled_shuffled.skip(num_validation_samples)\n","\n","# let's now define a batch size and batch the train data\n","batch_size = 100\n","train_data = train_data.batch(batch_size)\n","\n","# batch the validation data\n","validation_data = validation_data.batch(num_validation_samples)\n","\n","# batch the test data\n","test_data = test_scaled.batch(num_test_samples)\n","\n","# as_supervised is a 2-tuple structure\n","# so take the next batch\n","validation_inputs, validation_targets = next(iter(validation_data))"],"metadata":{"id":"rLu-L8z35yp5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Outline the model**"],"metadata":{"id":"ClNFrkKqqYDi"}},{"cell_type":"code","source":["# our goal is to build a neural network with an input layer, output layer and 2 hidden layers\n","input_size = 784 # image size is 28 x 28\n","output_size = 10 # 10 classes (digits)\n","hidden_layer_size = 50 # I chose the same size for both hidden layers\n","\n","# define the model\n","model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28,28,1)),\n","                             tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # first hidden layer\n","                             tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # second hidden layer\n","                             tf.keras.layers.Dense(output_size, activation='softmax')]) # output layer\n","                             # the method Flatten reorders the input image (28,28,1) into a (784,) vector\n","                             # the method Dense implements: output = activation(dot(input,weight) + bias)"],"metadata":{"id":"vzx9kbuKqRXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the optimizer, the loss function and the metric \n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# since the labels are not one-hot encoded (integers) we use sparse_cross_entropy as a loss function"],"metadata":{"id":"xh1bcDAV50Oe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training**"],"metadata":{"id":"GP4MA55g-rrb"}},{"cell_type":"code","source":["# next step is to train our data\n","# we specify the train_data, the number of epochs and the validation data we created\n","model.fit(train_data, epochs=10, validation_data=(validation_inputs, validation_targets), verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0IbG8j19d_R","executionInfo":{"status":"ok","timestamp":1642374843932,"user_tz":-60,"elapsed":51339,"user":{"displayName":"Sofiane Ikkour","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12163968403439377340"}},"outputId":"5d302832-9b1a-49bb-d574-5004e29c5f5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","540/540 - 9s - loss: 0.4159 - accuracy: 0.8819 - val_loss: 0.2370 - val_accuracy: 0.9347 - 9s/epoch - 16ms/step\n","Epoch 2/10\n","540/540 - 4s - loss: 0.1900 - accuracy: 0.9455 - val_loss: 0.1732 - val_accuracy: 0.9488 - 4s/epoch - 8ms/step\n","Epoch 3/10\n","540/540 - 4s - loss: 0.1434 - accuracy: 0.9584 - val_loss: 0.1315 - val_accuracy: 0.9620 - 4s/epoch - 8ms/step\n","Epoch 4/10\n","540/540 - 4s - loss: 0.1180 - accuracy: 0.9658 - val_loss: 0.1164 - val_accuracy: 0.9647 - 4s/epoch - 8ms/step\n","Epoch 5/10\n","540/540 - 4s - loss: 0.1001 - accuracy: 0.9712 - val_loss: 0.1012 - val_accuracy: 0.9720 - 4s/epoch - 8ms/step\n","Epoch 6/10\n","540/540 - 4s - loss: 0.0862 - accuracy: 0.9745 - val_loss: 0.1027 - val_accuracy: 0.9695 - 4s/epoch - 8ms/step\n","Epoch 7/10\n","540/540 - 4s - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.0883 - val_accuracy: 0.9750 - 4s/epoch - 8ms/step\n","Epoch 8/10\n","540/540 - 4s - loss: 0.0675 - accuracy: 0.9791 - val_loss: 0.0732 - val_accuracy: 0.9790 - 4s/epoch - 8ms/step\n","Epoch 9/10\n","540/540 - 4s - loss: 0.0591 - accuracy: 0.9821 - val_loss: 0.0687 - val_accuracy: 0.9787 - 4s/epoch - 8ms/step\n","Epoch 10/10\n","540/540 - 4s - loss: 0.0540 - accuracy: 0.9838 - val_loss: 0.0618 - val_accuracy: 0.9790 - 4s/epoch - 8ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f735a075590>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["**Testing**"],"metadata":{"id":"D5mHf4vRAeBb"}},{"cell_type":"code","source":["# after training our model, we need to test it on the test data \n","test_loss, test_accuracy = model.evaluate(test_data) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOkMussyAcZ9","executionInfo":{"status":"ok","timestamp":1642374853183,"user_tz":-60,"elapsed":1369,"user":{"displayName":"Sofiane Ikkour","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12163968403439377340"}},"outputId":"0d63fa3d-db2e-46b3-c57a-6d444a0aeb67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step - loss: 0.1039 - accuracy: 0.9692\n"]}]},{"cell_type":"code","source":["print('The test loss of our model is', round(test_loss*100,2),'%')\n","print('The test accuracy of our model is', round(test_accuracy*100,2),'%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbQNIjm-DfTu","executionInfo":{"status":"ok","timestamp":1642374860990,"user_tz":-60,"elapsed":253,"user":{"displayName":"Sofiane Ikkour","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12163968403439377340"}},"outputId":"f6084325-0cd4-45e2-c18b-14f6128a692d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The test loss of our model is 10.39 %\n","The test accuracy of our model is 96.92 %\n"]}]},{"cell_type":"markdown","source":["**Hyperparameter optimiztion**"],"metadata":{"id":"63w2Mf6mETCz"}},{"cell_type":"markdown","source":["Many adjustements have been applied in order to improve the accuracy of the model. \n","Please refer to the \"Optimized Deep Neural Network for MNIST Classification_Sofiane_Ikkour\" notebook to see the adjustements made."],"metadata":{"id":"D9QXaZPUGruL"}}]}